{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6eedbb-78ac-4e7b-bed5-15f06a2d9946",
   "metadata": {},
   "source": [
    "# Lab 15: Random numbers & Monte Carlo Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8562f-288d-47c6-92a2-0beaaf0fb7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A few import statements to start\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import stats\n",
    "\n",
    "# Set style for better-looking plots\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "np.random.seed(42)  # For reproducibility - can be changed if you want 'random' results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2580c318-5e00-42ce-843b-c793f06adf47",
   "metadata": {},
   "source": [
    "### Activty 1: Examining Random Number Distrobutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661744b1-5bae-4b15-a253-262795a6876d",
   "metadata": {},
   "source": [
    "Understanding how random numbers are generated and verifying their distributions is crucial for Monte Carlo methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8c3bde-e50e-43b5-a138-28321025c439",
   "metadata": {},
   "source": [
    "Part 1: Run the code cell below to examine uniform distrobution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c85cfa9-37a3-407d-844e-eef9275c840e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate uniform random numbers\n",
    "n_samples = 100000\n",
    "uniform_samples = np.random.uniform(0, 1, n_samples)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(uniform_samples, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "axes[0].axhline(y=1.0, color='r', linestyle='--', label='Theoretical PDF')\n",
    "axes[0].set_xlabel('Value')\n",
    "axes[0].set_ylabel('Probability Density')\n",
    "axes[0].set_title('Uniform Distribution [0,1]')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sequential plot to show quasi-random behavior\n",
    "axes[1].plot(uniform_samples[:1000], 'o', markersize=2, alpha=0.6)\n",
    "axes[1].set_xlabel('Sample Index')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_title('Sequential Values (First 1000 samples)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean: {np.mean(uniform_samples):.4f} (Expected: 0.5000)\")\n",
    "print(f\"Std Dev: {np.std(uniform_samples):.4f} (Expected: {1/np.sqrt(12):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3125cac3-4436-45cf-a2e2-b6f0da1e131f",
   "metadata": {},
   "source": [
    "Part 2: Run the code cell below to examine the gaussian distrobution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f804b1-d7e5-44d7-a8c1-5cb463156377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate normal random numbers\n",
    "mu, sigma = 0, 1\n",
    "normal_samples = np.random.normal(mu, sigma, n_samples)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram with theoretical PDF\n",
    "axes[0].hist(normal_samples, bins=60, density=True, alpha=0.7, edgecolor='black', label='Samples')\n",
    "x = np.linspace(-4, 4, 100)\n",
    "axes[0].plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, label='Theoretical PDF')\n",
    "axes[0].set_xlabel('Value')\n",
    "axes[0].set_ylabel('Probability Density')\n",
    "axes[0].set_title('Normal Distribution N(0,1)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(normal_samples, dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot (Quantile-Quantile)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean: {np.mean(normal_samples):.4f} (Expected: {mu:.4f})\")\n",
    "print(f\"Std Dev: {np.std(normal_samples):.4f} (Expected: {sigma:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65673d60-b6da-47c6-8d92-19f76d2eb5d2",
   "metadata": {},
   "source": [
    "Part 3: Run the code below to examine other commonly encountered distrobutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b8b33-baa0-4536-bc86-e8157d257faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Exponential distribution\n",
    "lambda_param = 1.5\n",
    "exp_samples = np.random.exponential(1/lambda_param, n_samples)\n",
    "axes[0, 0].hist(exp_samples, bins=60, density=True, alpha=0.7, edgecolor='black')\n",
    "x = np.linspace(0, 5, 100)\n",
    "axes[0, 0].plot(x, lambda_param * np.exp(-lambda_param * x), 'r-', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Value')\n",
    "axes[0, 0].set_ylabel('Probability Density')\n",
    "axes[0, 0].set_title(f'Exponential Distribution (λ={lambda_param})')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Poisson distribution\n",
    "lambda_poisson = 5\n",
    "poisson_samples = np.random.poisson(lambda_poisson, n_samples)\n",
    "axes[0, 1].hist(poisson_samples, bins=range(0, 20), density=True, alpha=0.7, edgecolor='black')\n",
    "x_poisson = np.arange(0, 20)\n",
    "axes[0, 1].plot(x_poisson, stats.poisson.pmf(x_poisson, lambda_poisson), 'ro-', linewidth=2, markersize=6)\n",
    "axes[0, 1].set_xlabel('Value')\n",
    "axes[0, 1].set_ylabel('Probability Mass')\n",
    "axes[0, 1].set_title(f'Poisson Distribution (λ={lambda_poisson})')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Beta distribution\n",
    "alpha, beta = 2, 5\n",
    "beta_samples = np.random.beta(alpha, beta, n_samples)\n",
    "axes[1, 0].hist(beta_samples, bins=60, density=True, alpha=0.7, edgecolor='black')\n",
    "x = np.linspace(0, 1, 100)\n",
    "axes[1, 0].plot(x, stats.beta.pdf(x, alpha, beta), 'r-', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Value')\n",
    "axes[1, 0].set_ylabel('Probability Density')\n",
    "axes[1, 0].set_title(f'Beta Distribution (α={alpha}, β={beta})')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Gamma distribution\n",
    "k, theta = 2, 2\n",
    "gamma_samples = np.random.gamma(k, theta, n_samples)\n",
    "axes[1, 1].hist(gamma_samples, bins=60, density=True, alpha=0.7, edgecolor='black')\n",
    "x = np.linspace(0, 20, 100)\n",
    "axes[1, 1].plot(x, stats.gamma.pdf(x, k, scale=theta), 'r-', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Value')\n",
    "axes[1, 1].set_ylabel('Probability Density')\n",
    "axes[1, 1].set_title(f'Gamma Distribution (k={k}, θ={theta})')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2088e40-42ee-483f-8fe7-bc4de6cff1d2",
   "metadata": {},
   "source": [
    "Before moving on to the next activty, take a moment to change some of the values that describe the distrobutions in part 3 (e.g., $\\lambda, \\alpha, \\beta$) and examine the change in the resulting plots. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c616c6-7f9b-44a2-9f90-e44a5890b184",
   "metadata": {},
   "source": [
    "### Activity 2: Random Walks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ae492a-405f-4345-8a33-d67ab618463f",
   "metadata": {},
   "source": [
    "Random walks are commonly encountered in several physics contexts. Here we will examine random walks in 1, 2, and 3 dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c4c5f-712f-4da4-904c-687cd0f0de84",
   "metadata": {},
   "source": [
    "Part 1: The 1D Random Walk. Examine the code below, and run the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa86adf3-c682-4f05-8de8-935363e6ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_1d(n_steps, n_walks=1):\n",
    "    \"\"\"Simulate 1D random walk(s)\"\"\"\n",
    "    steps = np.random.choice([-1, 1], size=(n_walks, n_steps))\n",
    "    positions = np.cumsum(steps, axis=1)\n",
    "    # Add initial position (0)\n",
    "    positions = np.column_stack([np.zeros(n_walks), positions])\n",
    "    return positions\n",
    "\n",
    "n_steps = 1000\n",
    "n_walks = 10\n",
    "\n",
    "walks_1d = random_walk_1d(n_steps, n_walks)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Individual walks\n",
    "for i in range(n_walks):\n",
    "    axes[0].plot(walks_1d[i], alpha=0.7, linewidth=1)\n",
    "axes[0].set_xlabel('Step Number')\n",
    "axes[0].set_ylabel('Position')\n",
    "axes[0].set_title(f'1D Random Walks ({n_walks} walkers)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Distribution of final positions\n",
    "n_walks_large = 10000\n",
    "walks_large = random_walk_1d(n_steps, n_walks_large)\n",
    "final_positions = walks_large[:, -1]\n",
    "\n",
    "axes[1].hist(final_positions, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "x = np.linspace(final_positions.min(), final_positions.max(), 100)\n",
    "# Theoretical: normal distribution with variance = n_steps\n",
    "axes[1].plot(x, stats.norm.pdf(x, 0, np.sqrt(n_steps)), 'r-', linewidth=2, label='Theoretical')\n",
    "axes[1].set_xlabel('Final Position')\n",
    "axes[1].set_ylabel('Probability Density')\n",
    "axes[1].set_title(f'Final Position Distribution ({n_walks_large} walks)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean final position: {np.mean(final_positions):.2f} (Expected: 0)\")\n",
    "print(f\"Std of final position: {np.std(final_positions):.2f} (Expected: {np.sqrt(n_steps):.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c270434-d92e-4b63-88d7-38cff583fdb4",
   "metadata": {},
   "source": [
    "Try adjusting the number of steps and walkers and rerun. How does this change the result? Does it make sense given what we know about these types of simulations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3856d34a-8240-4560-995b-5073f141f5f8",
   "metadata": {},
   "source": [
    "Part 2: The 2D Random Walk. Examine the code below, and run the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a60274-6b93-49f7-a30a-5b8c138e1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_2d(n_steps):\n",
    "    \"\"\"Simulate a 2D random walk\"\"\"\n",
    "    # Random angles for each step\n",
    "    angles = np.random.uniform(0, 2*np.pi, n_steps)\n",
    "    \n",
    "    # Unit step in each direction\n",
    "    dx = np.cos(angles)\n",
    "    dy = np.sin(angles)\n",
    "    \n",
    "    # Cumulative sum to get positions\n",
    "    x = np.cumsum(np.concatenate([[0], dx]))\n",
    "    y = np.cumsum(np.concatenate([[0], dy]))\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "n_steps = 2000\n",
    "n_walks = 5\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot multiple walks\n",
    "for i in range(n_walks):\n",
    "    x, y = random_walk_2d(n_steps)\n",
    "    axes[0].plot(x, y, alpha=0.6, linewidth=0.8)\n",
    "    axes[0].plot(x[0], y[0], 'go', markersize=8, label='Start' if i == 0 else '')\n",
    "    axes[0].plot(x[-1], y[-1], 'ro', markersize=8, label='End' if i == 0 else '')\n",
    "\n",
    "axes[0].set_xlabel('X Position')\n",
    "axes[0].set_ylabel('Y Position')\n",
    "axes[0].set_title(f'2D Random Walks ({n_steps} steps each)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axis('equal')\n",
    "\n",
    "# Distance from origin over time\n",
    "n_walks_dist = 100\n",
    "distances = np.zeros((n_walks_dist, n_steps + 1))\n",
    "\n",
    "for i in range(n_walks_dist):\n",
    "    x, y = random_walk_2d(n_steps)\n",
    "    distances[i] = np.sqrt(x**2 + y**2)\n",
    "\n",
    "mean_distance = np.mean(distances, axis=0)\n",
    "std_distance = np.std(distances, axis=0)\n",
    "\n",
    "steps = np.arange(n_steps + 1)\n",
    "axes[1].plot(steps, mean_distance, 'b-', linewidth=2, label='Mean distance')\n",
    "axes[1].fill_between(steps, mean_distance - std_distance, mean_distance + std_distance, \n",
    "                       alpha=0.3, label='±1 std dev')\n",
    "axes[1].plot(steps, np.sqrt(steps), 'r--', linewidth=2, label='√t (theoretical)')\n",
    "axes[1].set_xlabel('Step Number')\n",
    "axes[1].set_ylabel('Distance from Origin')\n",
    "axes[1].set_title(f'Mean Distance vs Time ({n_walks_dist} walks)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final mean distance: {mean_distance[-1]:.2f}\")\n",
    "print(f\"Theoretical expectation: {np.sqrt(n_steps):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4d17fb-07b4-4242-91d7-853484cf9f16",
   "metadata": {},
   "source": [
    "Try adjusting the number of steps and walkers and rerun. How does this change the result? Does it make sense given what we know about these types of simulations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead9ec1-ad24-4e38-860b-9ecdf37052a0",
   "metadata": {},
   "source": [
    "Part 3: The 3D Random Walk. Examine the code below, and run the cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c82c6-74bd-40b6-b86f-578b5dfecbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_3d(n_steps):\n",
    "    \"\"\"Simulate a 3D random walk\"\"\"\n",
    "    # Random direction on unit sphere using spherical coordinates\n",
    "    theta = np.random.uniform(0, 2*np.pi, n_steps)  # azimuthal angle\n",
    "    phi = np.arccos(np.random.uniform(-1, 1, n_steps))  # polar angle\n",
    "    \n",
    "    # Unit step in each direction\n",
    "    dx = np.sin(phi) * np.cos(theta)\n",
    "    dy = np.sin(phi) * np.sin(theta)\n",
    "    dz = np.cos(phi)\n",
    "    \n",
    "    # Cumulative sum to get positions\n",
    "    x = np.cumsum(np.concatenate([[0], dx]))\n",
    "    y = np.cumsum(np.concatenate([[0], dy]))\n",
    "    z = np.cumsum(np.concatenate([[0], dz]))\n",
    "    \n",
    "    return x, y, z\n",
    "\n",
    "n_steps = 500\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 3D trajectory\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "x, y, z = random_walk_3d(n_steps)\n",
    "\n",
    "# Color by time\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(x)))\n",
    "for i in range(len(x)-1):\n",
    "    ax1.plot(x[i:i+2], y[i:i+2], z[i:i+2], color=colors[i], linewidth=0.8)\n",
    "\n",
    "ax1.plot([x[0]], [y[0]], [z[0]], 'go', markersize=10, label='Start')\n",
    "ax1.plot([x[-1]], [y[-1]], [z[-1]], 'ro', markersize=10, label='End')\n",
    "ax1.set_xlabel('X')\n",
    "ax1.set_ylabel('Y')\n",
    "ax1.set_zlabel('Z')\n",
    "ax1.set_title('3D Random Walk')\n",
    "ax1.legend()\n",
    "\n",
    "# Distance from origin\n",
    "ax2 = fig.add_subplot(132)\n",
    "distances_3d = np.sqrt(x**2 + y**2 + z**2)\n",
    "ax2.plot(distances_3d, linewidth=2)\n",
    "ax2.plot(np.sqrt(np.arange(len(distances_3d))), 'r--', linewidth=2, alpha=0.7, label='√t')\n",
    "ax2.set_xlabel('Step Number')\n",
    "ax2.set_ylabel('Distance from Origin')\n",
    "ax2.set_title('Distance vs Time')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution of final positions (many walks)\n",
    "ax3 = fig.add_subplot(133)\n",
    "n_walks = 5000\n",
    "final_distances = []\n",
    "\n",
    "for _ in range(n_walks):\n",
    "    x, y, z = random_walk_3d(n_steps)\n",
    "    final_distances.append(np.sqrt(x[-1]**2 + y[-1]**2 + z[-1]**2))\n",
    "\n",
    "ax3.hist(final_distances, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "ax3.set_xlabel('Final Distance from Origin')\n",
    "ax3.set_ylabel('Probability Density')\n",
    "ax3.set_title(f'Final Distance Distribution ({n_walks} walks)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean final distance: {np.mean(final_distances):.2f}\")\n",
    "print(f\"Std of final distance: {np.std(final_distances):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1673cf85-0b07-4f04-9088-68efe69fc267",
   "metadata": {},
   "source": [
    "Try adjusting the number of steps and rerun (e.g., 1000, 5000, 10000, etc.). How does this change the result? Note that this simulation is unlike the prior two cases because we only consider a single walker. But with each subsequent run, it is like a 'new' walker each time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df064771-6149-4587-ae3a-5b1aca96312c",
   "metadata": {},
   "source": [
    "### Activity 3: Markov Chain Monte Carlo (MCMC) - Metropolis-Hastings Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa21958-413e-42e4-ab13-129c51089f32",
   "metadata": {},
   "source": [
    "Run the cell below to examine sampling with a complex posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08acfa2c-bc35-4480-9233-072041a60b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(target_pdf, initial, n_samples, proposal_std=1.0):\n",
    "    \"\"\"\n",
    "    Metropolis-Hastings MCMC algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    target_pdf : function\n",
    "        Target probability density function (unnormalized is OK)\n",
    "    initial : float\n",
    "        Initial value\n",
    "    n_samples : int\n",
    "        Number of samples to generate\n",
    "    proposal_std : float\n",
    "        Standard deviation of proposal distribution (Gaussian random walk)\n",
    "    \"\"\"\n",
    "    samples = np.zeros(n_samples)\n",
    "    samples[0] = initial\n",
    "    \n",
    "    current = initial\n",
    "    current_pdf = target_pdf(current)\n",
    "    \n",
    "    n_accepted = 0\n",
    "    \n",
    "    for i in range(1, n_samples):\n",
    "        # Propose new state\n",
    "        proposed = current + np.random.normal(0, proposal_std)\n",
    "        proposed_pdf = target_pdf(proposed)\n",
    "        \n",
    "        # Acceptance probability\n",
    "        acceptance_prob = min(1, proposed_pdf / current_pdf)\n",
    "        \n",
    "        # Accept or reject\n",
    "        if np.random.random() < acceptance_prob:\n",
    "            current = proposed\n",
    "            current_pdf = proposed_pdf\n",
    "            n_accepted += 1\n",
    "        \n",
    "        samples[i] = current\n",
    "    \n",
    "    acceptance_rate = n_accepted / n_samples\n",
    "    return samples, acceptance_rate\n",
    "\n",
    "# Example: Sample from a mixture of Gaussians \n",
    "def target_distribution(x):\n",
    "    return 0.3 * np.exp(-0.5 * ((x + 2) / 0.5)**2) + \\\n",
    "           0.7 * np.exp(-0.5 * ((x - 2) / 1.0)**2)\n",
    "\n",
    "n_samples = 20000\n",
    "initial = 0.0\n",
    "samples, acceptance_rate = metropolis_hastings(target_distribution, initial, n_samples, proposal_std=2.0)\n",
    "\n",
    "# Discard burn-in\n",
    "burn_in = 1000\n",
    "samples_burned = samples[burn_in:]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Trace plot\n",
    "axes[0, 0].plot(samples[:2000], linewidth=0.5)\n",
    "axes[0, 0].axvline(x=burn_in, color='r', linestyle='--', label=f'Burn-in = {burn_in}')\n",
    "axes[0, 0].set_xlabel('Sample Index')\n",
    "axes[0, 0].set_ylabel('Sample Value')\n",
    "axes[0, 0].set_title('Trace Plot (First 2000 samples)')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram with target\n",
    "x_plot = np.linspace(-5, 5, 1000)\n",
    "target_vals = np.array([target_distribution(x) for x in x_plot])\n",
    "target_vals = target_vals / np.trapz(target_vals, x_plot)  # Normalize\n",
    "\n",
    "axes[0, 1].hist(samples_burned, bins=60, density=True, alpha=0.7, edgecolor='black', label='MCMC Samples')\n",
    "axes[0, 1].plot(x_plot, target_vals, 'r-', linewidth=2, label='Target PDF')\n",
    "axes[0, 1].set_xlabel('x')\n",
    "axes[0, 1].set_ylabel('Probability Density')\n",
    "axes[0, 1].set_title(f'MCMC Samples vs Target (Acceptance: {acceptance_rate:.2%})')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Autocorrelation\n",
    "from numpy import correlate\n",
    "def autocorr(x, max_lag=100):\n",
    "    x = x - np.mean(x)\n",
    "    result = np.array([1] + [np.corrcoef(x[:-i], x[i:])[0,1] for i in range(1, max_lag)])\n",
    "    return result\n",
    "\n",
    "acf = autocorr(samples_burned, max_lag=100)\n",
    "axes[1, 0].plot(acf, 'o-', markersize=3, linewidth=1)\n",
    "axes[1, 0].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "axes[1, 0].set_xlabel('Lag')\n",
    "axes[1, 0].set_ylabel('Autocorrelation')\n",
    "axes[1, 0].set_title('Autocorrelation Function')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Running mean\n",
    "running_mean = np.cumsum(samples) / np.arange(1, len(samples) + 1)\n",
    "axes[1, 1].plot(running_mean, linewidth=1)\n",
    "axes[1, 1].axhline(y=np.mean(samples_burned), color='r', linestyle='--', \n",
    "                   label=f'Final mean: {np.mean(samples_burned):.3f}')\n",
    "axes[1, 1].axvline(x=burn_in, color='g', linestyle='--', alpha=0.5, label='Burn-in')\n",
    "axes[1, 1].set_xlabel('Sample Index')\n",
    "axes[1, 1].set_ylabel('Running Mean')\n",
    "axes[1, 1].set_title('Convergence of Mean')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Acceptance rate: {acceptance_rate:.2%}\")\n",
    "print(f\"Mean of samples: {np.mean(samples_burned):.4f}\")\n",
    "print(f\"Std of samples: {np.std(samples_burned):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175abfb9-39a3-4af8-8518-ddd256887905",
   "metadata": {},
   "source": [
    "Note we are able to match well with the target probability distrobution using this algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8cb8c-d5b5-4864-a2b8-76e98f4399c3",
   "metadata": {},
   "source": [
    "Now we'll turn to another example use MCMC to estimate parameters of a simple linear model given noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699d030-7d42-4d69-a0c3-2fcbfecee986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data: y = a*x + b + noise\n",
    "np.random.seed(42)\n",
    "true_a = 2.5\n",
    "true_b = 1.0\n",
    "noise_std = 0.5\n",
    "\n",
    "x_data = np.linspace(0, 10, 50)\n",
    "y_data = true_a * x_data + true_b + np.random.normal(0, noise_std, len(x_data))\n",
    "\n",
    "# Define log-likelihood and log-prior\n",
    "def log_likelihood(params, x, y, sigma):\n",
    "    a, b = params\n",
    "    y_model = a * x + b\n",
    "    return -0.5 * np.sum(((y - y_model) / sigma)**2)\n",
    "\n",
    "def log_prior(params):\n",
    "    a, b = params\n",
    "    # Uniform priors: a in [0, 5], b in [-2, 4]\n",
    "    if 0 < a < 5 and -2 < b < 4:\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "def log_posterior(params, x, y, sigma):\n",
    "    lp = log_prior(params)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    return lp + log_likelihood(params, x, y, sigma)\n",
    "\n",
    "# MCMC sampler for 2D parameter space\n",
    "def mcmc_2d(log_prob_func, initial, n_samples, proposal_std=0.1):\n",
    "    n_params = len(initial)\n",
    "    samples = np.zeros((n_samples, n_params))\n",
    "    samples[0] = initial\n",
    "    \n",
    "    current = initial\n",
    "    current_log_prob = log_prob_func(current)\n",
    "    \n",
    "    n_accepted = 0\n",
    "    \n",
    "    for i in range(1, n_samples):\n",
    "        # Propose new state\n",
    "        proposed = current + np.random.normal(0, proposal_std, n_params)\n",
    "        proposed_log_prob = log_prob_func(proposed)\n",
    "        \n",
    "        # Acceptance probability (in log space)\n",
    "        log_acceptance = proposed_log_prob - current_log_prob\n",
    "        \n",
    "        # Accept or reject\n",
    "        if np.log(np.random.random()) < log_acceptance:\n",
    "            current = proposed\n",
    "            current_log_prob = proposed_log_prob\n",
    "            n_accepted += 1\n",
    "        \n",
    "        samples[i] = current\n",
    "    \n",
    "    return samples, n_accepted / n_samples\n",
    "\n",
    "# Run MCMC\n",
    "n_samples = 10000\n",
    "initial = np.array([2.0, 0.5])\n",
    "samples, acceptance_rate = mcmc_2d(\n",
    "    lambda params: log_posterior(params, x_data, y_data, noise_std),\n",
    "    initial, n_samples, proposal_std=0.05\n",
    ")\n",
    "\n",
    "# Discard burn-in\n",
    "burn_in = 1000\n",
    "samples_burned = samples[burn_in:]\n",
    "\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Data and fit\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.plot(x_data, y_data, 'ko', markersize=6, alpha=0.6, label='Data')\n",
    "\n",
    "# Plot samples from posterior\n",
    "for i in np.random.choice(len(samples_burned), 100):\n",
    "    a_sample, b_sample = samples_burned[i]\n",
    "    ax1.plot(x_data, a_sample * x_data + b_sample, 'b-', alpha=0.02, linewidth=1)\n",
    "\n",
    "# Best fit (posterior mean)\n",
    "a_mean = np.mean(samples_burned[:, 0])\n",
    "b_mean = np.mean(samples_burned[:, 1])\n",
    "ax1.plot(x_data, a_mean * x_data + b_mean, 'r-', linewidth=3, \n",
    "         label=f'Fit: y = {a_mean:.3f}x + {b_mean:.3f}')\n",
    "ax1.plot(x_data, true_a * x_data + true_b, 'g--', linewidth=2, \n",
    "         label=f'True: y = {true_a}x + {true_b}')\n",
    "\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('y')\n",
    "ax1.set_title('Data and Posterior Samples')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Trace plots\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "ax2.plot(samples[:, 0], linewidth=0.5)\n",
    "ax2.axvline(x=burn_in, color='r', linestyle='--', alpha=0.5)\n",
    "ax2.axhline(y=true_a, color='g', linestyle='--', alpha=0.5, label='True value')\n",
    "ax2.set_xlabel('Sample')\n",
    "ax2.set_ylabel('a (slope)')\n",
    "ax2.set_title('Trace: Slope')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.plot(samples[:, 1], linewidth=0.5)\n",
    "ax3.axvline(x=burn_in, color='r', linestyle='--', alpha=0.5)\n",
    "ax3.axhline(y=true_b, color='g', linestyle='--', alpha=0.5, label='True value')\n",
    "ax3.set_xlabel('Sample')\n",
    "ax3.set_ylabel('b (intercept)')\n",
    "ax3.set_title('Trace: Intercept')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 2D histogram (joint posterior)\n",
    "ax4 = fig.add_subplot(gs[1, 2])\n",
    "h = ax4.hist2d(samples_burned[:, 0], samples_burned[:, 1], bins=50, cmap='Blues')\n",
    "ax4.plot(true_a, true_b, 'r*', markersize=20, label='True values')\n",
    "ax4.plot(a_mean, b_mean, 'go', markersize=10, label='Posterior mean')\n",
    "ax4.set_xlabel('a (slope)')\n",
    "ax4.set_ylabel('b (intercept)')\n",
    "ax4.set_title('Joint Posterior')\n",
    "ax4.legend()\n",
    "plt.colorbar(h[3], ax=ax4, label='Density')\n",
    "\n",
    "# Marginal distributions\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "ax5.hist(samples_burned[:, 0], bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "ax5.axvline(x=true_a, color='r', linestyle='--', linewidth=2, label='True value')\n",
    "ax5.axvline(x=a_mean, color='g', linestyle='--', linewidth=2, label='Posterior mean')\n",
    "ax5.set_xlabel('a (slope)')\n",
    "ax5.set_ylabel('Probability Density')\n",
    "ax5.set_title('Marginal: Slope')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "ax6.hist(samples_burned[:, 1], bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "ax6.axvline(x=true_b, color='r', linestyle='--', linewidth=2, label='True value')\n",
    "ax6.axvline(x=b_mean, color='g', linestyle='--', linewidth=2, label='Posterior mean')\n",
    "ax6.set_xlabel('b (intercept)')\n",
    "ax6.set_ylabel('Probability Density')\n",
    "ax6.set_title('Marginal: Intercept')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Correlation\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "correlation = np.corrcoef(samples_burned.T)[0, 1]\n",
    "ax7.text(0.5, 0.6, f'Acceptance Rate: {acceptance_rate:.2%}', \n",
    "         ha='center', va='center', fontsize=14, transform=ax7.transAxes)\n",
    "ax7.text(0.5, 0.5, f'Correlation(a,b): {correlation:.3f}', \n",
    "         ha='center', va='center', fontsize=14, transform=ax7.transAxes)\n",
    "ax7.text(0.5, 0.4, f'a = {a_mean:.3f} ± {np.std(samples_burned[:, 0]):.3f}', \n",
    "         ha='center', va='center', fontsize=12, transform=ax7.transAxes)\n",
    "ax7.text(0.5, 0.3, f'b = {b_mean:.3f} ± {np.std(samples_burned[:, 1]):.3f}', \n",
    "         ha='center', va='center', fontsize=12, transform=ax7.transAxes)\n",
    "ax7.text(0.5, 0.2, f'True: a={true_a}, b={true_b}', \n",
    "         ha='center', va='center', fontsize=12, transform=ax7.transAxes, color='red')\n",
    "ax7.set_xlim(0, 1)\n",
    "ax7.set_ylim(0, 1)\n",
    "ax7.axis('off')\n",
    "ax7.set_title('Summary Statistics')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nParameter Estimates:\")\n",
    "print(f\"Slope (a): {a_mean:.4f} ± {np.std(samples_burned[:, 0]):.4f} (True: {true_a})\")\n",
    "print(f\"Intercept (b): {b_mean:.4f} ± {np.std(samples_burned[:, 1]):.4f} (True: {true_b})\")\n",
    "print(f\"Correlation: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93814f-5bb6-4cf8-90d9-503abbc6b530",
   "metadata": {},
   "source": [
    "Note this methodology can be extended to fits of much more complex data. This admittedly is 'overkill' for 1D, but the strengths of MCMC lie in multidimensional cases where other methods fail. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b9b91b-64f4-4eed-af8b-b7e3d3656834",
   "metadata": {},
   "source": [
    "### Activity 4: The Ising Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4083ca-7868-4431-bfd4-1545486c1d9b",
   "metadata": {},
   "source": [
    "The Ising model is a mathematical model of ferromagnetism in statistical mechanics. It's one of the most studied models in computational physics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476925f9-8d7e-4e38-ad04-4b3d508082f6",
   "metadata": {},
   "source": [
    "The model consists of discrete variables that represent magnetic dipole moments of atomic \"spins\" that can be in one of two states (+1 or −1). The spins are arranged on a lattice, allowing each spin to interact with its neighbors. Neighboring spins that agree have a lower energy than those that disagree; the system tends to the lowest energy but heat disturbs this tendency, thus creating the possibility of different structural phases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac6220d-cb62-47cf-8067-c915a0d07591",
   "metadata": {},
   "source": [
    "The suite of functions below will be used to make an simulation of the Ising model. You can read more about the specific mathematics behind the model here: https://en.wikipedia.org/wiki/Ising_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1089fa3d-57d9-4cdb-af24-8843489ef336",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IsingModel:\n",
    "    def __init__(self, size, temperature):\n",
    "        \"\"\"\n",
    "        Initialize Ising model on a square lattice\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        size : int\n",
    "            Size of the lattice (size x size)\n",
    "        temperature : float\n",
    "            Temperature in units of J/k_B (J = coupling constant)\n",
    "        \"\"\"\n",
    "        self.size = size\n",
    "        self.T = temperature\n",
    "        self.lattice = np.random.choice([-1, 1], size=(size, size))\n",
    "        \n",
    "    def energy(self):\n",
    "        \"\"\"Calculate total energy of the system\"\"\"\n",
    "        E = 0\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                S = self.lattice[i, j]\n",
    "                # Sum over nearest neighbors with periodic boundary conditions\n",
    "                neighbors = self.lattice[(i+1) % self.size, j] + \\\n",
    "                           self.lattice[i, (j+1) % self.size] + \\\n",
    "                           self.lattice[(i-1) % self.size, j] + \\\n",
    "                           self.lattice[i, (j-1) % self.size]\n",
    "                E += -S * neighbors\n",
    "        return E / 2.0  # Divide by 2 to avoid double counting\n",
    "    \n",
    "    def magnetization(self):\n",
    "        \"\"\"Calculate total magnetization\"\"\"\n",
    "        return np.sum(self.lattice)\n",
    "    \n",
    "    def monte_carlo_step(self):\n",
    "        \"\"\"Perform one Monte Carlo step (one sweep through the lattice)\"\"\"\n",
    "        for _ in range(self.size**2):\n",
    "            # Pick random spin\n",
    "            i = np.random.randint(0, self.size)\n",
    "            j = np.random.randint(0, self.size)\n",
    "            S = self.lattice[i, j]\n",
    "            \n",
    "            # Calculate energy change if we flip this spin\n",
    "            neighbors = self.lattice[(i+1) % self.size, j] + \\\n",
    "                       self.lattice[i, (j+1) % self.size] + \\\n",
    "                       self.lattice[(i-1) % self.size, j] + \\\n",
    "                       self.lattice[i, (j-1) % self.size]\n",
    "            \n",
    "            dE = 2 * S * neighbors\n",
    "            \n",
    "            # Metropolis algorithm\n",
    "            if dE < 0 or np.random.random() < np.exp(-dE / self.T):\n",
    "                self.lattice[i, j] = -S\n",
    "    \n",
    "    def simulate(self, n_steps, measure_interval=1):\n",
    "        \"\"\"Run Monte Carlo simulation\"\"\"\n",
    "        energies = []\n",
    "        magnetizations = []\n",
    "        \n",
    "        for step in range(n_steps):\n",
    "            self.monte_carlo_step()\n",
    "            \n",
    "            if step % measure_interval == 0:\n",
    "                energies.append(self.energy())\n",
    "                magnetizations.append(abs(self.magnetization()))\n",
    "        \n",
    "        return energies, magnetizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24b5fd-8ebb-414a-a70d-57a947c26195",
   "metadata": {},
   "source": [
    "Let's start by visualizing the ising model results at different temperatures to look at magnetic domain structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c90482-00ff-48a8-961b-9bc34ba9e233",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 25 #size of grid to consider\n",
    "n_equilibration = 1000 # steps to reach equilibrium in sim. \n",
    "temperatures = [1.0, 2.0, 2.269, 3.0, 4.0]  # T_c ≈ 2.269 for 2D Ising model\n",
    "\n",
    "fig, axes = plt.subplots(1, len(temperatures), figsize=(20, 4))\n",
    "\n",
    "for idx, T in enumerate(temperatures):\n",
    "    model = IsingModel(size, T)\n",
    "    \n",
    "    # Equilibrate\n",
    "    for _ in range(n_equilibration):\n",
    "        model.monte_carlo_step()\n",
    "    \n",
    "    # Plot\n",
    "    im = axes[idx].imshow(model.lattice, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    axes[idx].set_title(f'T = {T:.3f}' + (' (< Tc)' if T < 2.269 else ' (> Tc)' if T > 2.269 else ' (≈ Tc)'))\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.colorbar(im, ax=axes, orientation='horizontal', fraction=0.046, pad=0.04, label='Spin')\n",
    "#plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Note: Tc ≈ 2.269 is the critical temperature for the 2D Ising model\")\n",
    "print(\"Below Tc: Ordered (ferromagnetic) phase\")\n",
    "print(\"Above Tc: Disordered (paramagnetic) phase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d00c69-d3eb-4a55-94d0-c92beb043d3d",
   "metadata": {},
   "source": [
    "Next, let's examine time evolution of the simulation and related thermodynamic properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb1ae7-83d1-47a3-8435-c225d6327aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters. Select range of temperatures near the critical temperature\n",
    "size = 25\n",
    "T_low = 1.5\n",
    "T_high = 3.0\n",
    "n_steps = 1000\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Low temperature\n",
    "model_low = IsingModel(size, T_low)\n",
    "energies_low, mags_low = model_low.simulate(n_steps)\n",
    "\n",
    "axes[0, 0].plot(energies_low, linewidth=1)\n",
    "axes[0, 0].set_xlabel('Monte Carlo Step')\n",
    "axes[0, 0].set_ylabel('Energy')\n",
    "axes[0, 0].set_title(f'Energy Evolution (T={T_low})')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(np.array(mags_low) / size**2, linewidth=1)\n",
    "axes[0, 1].set_xlabel('Monte Carlo Step')\n",
    "axes[0, 1].set_ylabel('Magnetization per Spin')\n",
    "axes[0, 1].set_title(f'Magnetization Evolution (T={T_low})')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# High temperature\n",
    "model_high = IsingModel(size, T_high)\n",
    "energies_high, mags_high = model_high.simulate(n_steps)\n",
    "\n",
    "axes[1, 0].plot(energies_high, linewidth=1)\n",
    "axes[1, 0].set_xlabel('Monte Carlo Step')\n",
    "axes[1, 0].set_ylabel('Energy')\n",
    "axes[1, 0].set_title(f'Energy Evolution (T={T_high})')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(np.array(mags_high) / size**2, linewidth=1)\n",
    "axes[1, 1].set_xlabel('Monte Carlo Step')\n",
    "axes[1, 1].set_ylabel('Magnetization per Spin')\n",
    "axes[1, 1].set_title(f'Magnetization Evolution (T={T_high})')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5d32c9-c025-4f32-89a1-c0734ada58f8",
   "metadata": {},
   "source": [
    "Finally, let's take a look at the 'phase transition' of the magnetic state (Note this cell is very slow and may take a while to run!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13bf7c-9fc5-4017-abc5-f12bea61265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 25\n",
    "temperatures = np.linspace(1.0, 4.0, 20)\n",
    "n_equilibration = 1000\n",
    "n_measurement = 500\n",
    "\n",
    "mean_energies = []\n",
    "mean_magnetizations = []\n",
    "heat_capacities = []\n",
    "susceptibilities = []\n",
    "\n",
    "for T in temperatures:\n",
    "    model = IsingModel(size, T)\n",
    "    \n",
    "    # Equilibration\n",
    "    for _ in range(n_equilibration):\n",
    "        model.monte_carlo_step()\n",
    "    \n",
    "    # Measurement\n",
    "    energies = []\n",
    "    magnetizations = []\n",
    "    \n",
    "    for _ in range(n_measurement):\n",
    "        model.monte_carlo_step()\n",
    "        energies.append(model.energy())\n",
    "        magnetizations.append(abs(model.magnetization()))\n",
    "    \n",
    "    # Calculate thermodynamic quantities\n",
    "    E = np.array(energies) / size**2\n",
    "    M = np.array(magnetizations) / size**2\n",
    "    \n",
    "    mean_energies.append(np.mean(E))\n",
    "    mean_magnetizations.append(np.mean(M))\n",
    "    \n",
    "    # Heat capacity: C = (⟨E²⟩ - ⟨E⟩²) / T²\n",
    "    heat_capacities.append((np.mean(E**2) - np.mean(E)**2) / T**2)\n",
    "    \n",
    "    # Magnetic susceptibility: χ = (⟨M²⟩ - ⟨M⟩²) / T\n",
    "    susceptibilities.append((np.mean(M**2) - np.mean(M)**2) / T)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axes[0, 0].plot(temperatures, mean_energies, 'o-', linewidth=2)\n",
    "axes[0, 0].axvline(x=2.269, color='r', linestyle='--', label='Tc ≈ 2.269')\n",
    "axes[0, 0].set_xlabel('Temperature')\n",
    "axes[0, 0].set_ylabel('Energy per Spin')\n",
    "axes[0, 0].set_title('Average Energy')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[0, 1].plot(temperatures, mean_magnetizations, 'o-', linewidth=2)\n",
    "axes[0, 1].axvline(x=2.269, color='r', linestyle='--', label='Tc ≈ 2.269')\n",
    "axes[0, 1].set_xlabel('Temperature')\n",
    "axes[0, 1].set_ylabel('Magnetization per Spin')\n",
    "axes[0, 1].set_title('Average Magnetization')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 0].plot(temperatures, heat_capacities, 'o-', linewidth=2)\n",
    "axes[1, 0].axvline(x=2.269, color='r', linestyle='--', label='Tc ≈ 2.269')\n",
    "axes[1, 0].set_xlabel('Temperature')\n",
    "axes[1, 0].set_ylabel('Heat Capacity')\n",
    "axes[1, 0].set_title('Specific Heat')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].plot(temperatures, susceptibilities, 'o-', linewidth=2)\n",
    "axes[1, 1].axvline(x=2.269, color='r', linestyle='--', label='Tc ≈ 2.269')\n",
    "axes[1, 1].set_xlabel('Temperature')\n",
    "axes[1, 1].set_ylabel('Magnetic Susceptibility')\n",
    "axes[1, 1].set_title('Magnetic Susceptibility')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Phase transition is visible in:\")\n",
    "print(\"1. Magnetization: Drops sharply near Tc\")\n",
    "print(\"2. Heat capacity: Peaks at Tc\")\n",
    "print(\"3. Susceptibility: Peaks at Tc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d7596-3dd9-45ef-8dd9-ec94f312f971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
